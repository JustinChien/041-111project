{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9857ebcc-bbee-4d7b-b44a-ad8341c97457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,BatchNormalization,Input,LeakyReLU,Activation\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import prettytable as pt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373d5c6a-51af-486a-b657-3963c5e8bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Avaliable[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]:\n"
     ]
    }
   ],
   "source": [
    "#GPU FOR TRAINGING\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"GPUs Avaliable{}:\".format(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b810a1b9-30cd-4a0d-a5d2-b5aa14def4fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define some functions\n",
    "\n",
    "def join_path(root:str , *params)-> str:\n",
    "    # give root and folders / files will return a path in str\n",
    "    temp = root\n",
    "    for p in params:\n",
    "        temp = os.path.join(temp,p)\n",
    "    return temp\n",
    "\n",
    "#This will plot a binary or multiclass classification's confusion matrix\n",
    "def plot_confusion_matrix(cm, classes\n",
    "                          ,normalize = False\n",
    "                          ,title='Confusion matrix'\n",
    "                          ,cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes,rotation=45,fontsize=12)\n",
    "    plt.yticks(tick_marks,classes,fontsize=12)\n",
    "    if normalize :\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:,np/newaxis]\n",
    "        # print(\"Normalized confusion matrix\")\n",
    "    else :\n",
    "        # print(\"Confusion matrix\")\n",
    "        pass\n",
    "    # print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i , j in itertools.product(range(cm.shape[0]),range(cm.shape[1])): \n",
    "        plt.text(j,i,cm[i,j],\n",
    "                ha = \"center\",\n",
    "                fontsize = 15,\n",
    "                color = \"orange\" if cm[i,j]> thresh else \"purple\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "def plot_multi_label_confusion_matrix(cm,classes,cmap=plt.cm.Blues) -> None:\n",
    "    #give the whole ConfusionMatrix and classes and it will plot it out\n",
    "    fig,ax = plt.subplots(2,int(len(cm)/2))\n",
    "    count = 0\n",
    "    for a,b in itertools.product(range(2),range(int(len(cm)/2))):\n",
    "\n",
    "\n",
    "        thresh = cm[count].max() / 2.\n",
    "        temp_cm = cm[count]\n",
    "        class_ = classes[count]\n",
    "\n",
    "        # plt.figure(figsize=(6,6))\n",
    "        ax[a][b].imshow(temp_cm,interpolation='nearest',cmap=plt.cm.Blues)\n",
    "        ax[a][b].set_title(class_)\n",
    "\n",
    "        if(a == 0 and b==0):\n",
    "            ax[a][b].set_yticks(np.arange(2),[\"TrueNegative , FalsePositive\",\"FalseNegative , TruePositive \"])\n",
    "        else:\n",
    "            ax[a][b].set_yticks([])\n",
    "\n",
    "        ax[a][b].set_xticks([])\n",
    "        for i,j in itertools.product(range(len(temp_cm[:][0])),range(len(temp_cm[0][:]))):\n",
    "                ax[a][b].text(j,i,temp_cm[i][j],\n",
    "                        ha = \"center\",\n",
    "                        color = \"orange\" if temp_cm[i,j]> thresh else \"purple\")\n",
    "        count += 1\n",
    "\n",
    "def plot_acc_loss(acc,val_acc,loss,val_loss):\n",
    "    #give values from fit history and it will plot out a graph\n",
    "    plt.figure(figsize=(8,8))\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(acc,label=\"Trainging Accuracy\")\n",
    "    plt.plot(val_acc,label=\"Validation Accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(loss,label=\"Trainging Loss\")\n",
    "    plt.plot(val_loss,label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.ylabel(\"Cross Entropy\")\n",
    "    # plt.ylim([0,1.0]) #too high so let's not use this now\n",
    "    plt.title(\"Trainging and Validation Loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_imgs(lots_imgs,lots_labels):\n",
    "    # give 9 imgs and 9 lables,it will plot it out\n",
    "    imgs = lots_imgs[:9]\n",
    "    labels = lots_labels[:9]\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(len(imgs)):\n",
    "        ax = plt.subplot(3,3,i+1)\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.title(labels[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "def convert_cm_to_container(cm):\n",
    "    #give it a Multilabel Confusion Matrix and it will store it in a str, ez for storing in csv\n",
    "    cm_container = str()\n",
    "    if len(cm)==2:\n",
    "        for i ,j in itertools.product(range(len(cm)),range(2)):\n",
    "            cm_container += \"{}_\".format(cm[i,j])\n",
    "    else:\n",
    "        for i,j,k in itertools.product(range(len(cm)),range(2),range(2)):\n",
    "            cm_container += \"{}_\".format(cm[i,j,k])\n",
    "    return cm_container\n",
    "\n",
    "def convert_container_to_cm(cm_container):\n",
    "    #give it the str generate from function above,will return what it suppose to look like originally\n",
    "    temp = cm_container.split(sep=\"_\")\n",
    "    size = int((len(temp)-1)/4)\n",
    "    # print(size)\n",
    "    if size == 4 or size == 6:\n",
    "        c_cm = np.empty((size,2,2))\n",
    "        count = -1\n",
    "        for i,j,k in itertools.product(range(size),range(2),range(2)):\n",
    "            count += 1\n",
    "            # print(count)\n",
    "            c_cm[i,j,k] = temp[count]\n",
    "    elif size == 1:\n",
    "        c_cm = np.empty((2,2))\n",
    "        count = -1\n",
    "        for i,j in itertools.product(range(2),range(2)):\n",
    "            count += 1\n",
    "            # print(count)\n",
    "            c_cm[i,j] = temp[count]\n",
    "    return c_cm\n",
    "\n",
    "def convert_list_to_str(list_:list) -> str:\n",
    "    temp = str()\n",
    "    for item in list_:\n",
    "        temp += \"{}_\".format(item)\n",
    "    return temp\n",
    "\n",
    "def convert_str_to_list(str_:str) -> list:\n",
    "    list_ = list()\n",
    "    str_ = str_.split(sep='_')\n",
    "    for item in str_[:-1]:\n",
    "        list_.append(float(item))\n",
    "    return list_\n",
    "\n",
    "def show_report(*nums, show_plot:bool=False):\n",
    "    #give nums to choose which data to show,CAN give multiplay nums at once\n",
    "    #if want to print out all history better use for loop with it\n",
    "    #show_plot will control whether to plot ConfusionMatrix or not\n",
    "    temp = list()\n",
    "    history_report = pd.read_csv(report_csv_path)\n",
    "\n",
    "    table = pt.PrettyTable()\n",
    "    table.set_style(pt.DOUBLE_BORDER)\n",
    "    table.hrules=pt.ALL\n",
    "    temp.append('index')\n",
    "    for num in nums:\n",
    "        temp.append(num)\n",
    "    table.field_names = temp\n",
    "\n",
    "    for column in [\"Date\",\"Model\",\"Batch_size\",\"epochs\",\"Learning_rate\",\"Training_Report\",\"DATA_TYPE\",\"Note\"]:\n",
    "        temp = []\n",
    "        temp.append(column)\n",
    "        for num in nums:\n",
    "            temp.append(history_report.iloc[num][column])\n",
    "        table.add_row(temp)\n",
    "    print(table)\n",
    "\n",
    "    if show_plot == True:\n",
    "        for num in nums:\n",
    "            current_cm = convert_container_to_cm(history_report.iloc[num]['Confusion_Matrix'])\n",
    "            # print(current_cm)\n",
    "            if len(current_cm)==6:\n",
    "                plot_multi_label_confusion_matrix(cm=current_cm,classes=['Benign', 'CC', 'Calc', 'MLO', 'Mass', 'Melignant'])\n",
    "            elif len(current_cm)==4:\n",
    "                plot_multi_label_confusion_matrix(cm=current_cm,classes=['Benign', 'Calc', 'Mass', 'Melignant'])\n",
    "            elif len(current_cm)==2:\n",
    "                plot_confusion_matrix(cm=current_cm,classes=['Benign','Malignant'])\n",
    "                \n",
    "            current_row = history_report.iloc[num]\n",
    "            if current_row.isnull()['acc']==True:\n",
    "                print('index:{} have no acuracy data for plotting accuracy.'.format(num))\n",
    "                continue\n",
    "            print(\"index:{}\".format(num))\n",
    "            acc = convert_str_to_list(current_row['acc'])\n",
    "            val_acc = convert_str_to_list(current_row['val_acc'])\n",
    "            loss = convert_str_to_list(current_row['loss'])\n",
    "            val_loss = convert_str_to_list(current_row['val_loss'])\n",
    "            # print(acc,'\\n',val_acc,'\\n',loss,'\\n',val_loss)\n",
    "            plot_acc_loss(acc=acc,val_acc=val_acc,loss=loss,val_loss=val_loss)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e11b998-b093-4665-a552-2e283aaf9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables and Constants\n",
    "DATA_TYPE = \"ALL\" #options: ALL,CC,MLO\n",
    "DATA_CLASS = ['Benign','Malignant']\n",
    "model_name = \"DenseNet\" #Options: MobileNet,Inception,VGG,DenseNet\n",
    "learning_rate = 1e-05\n",
    "epochs = 30\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224,224,3)\n",
    "show_detail = True\n",
    "\n",
    "\n",
    "X_dataset = list()\n",
    "IMG_DIR = \"D:\\\\111project\\\\gitHub\\\\041-111project\\\\data\\\\Cropped_Calc_imgs\"\n",
    "report_csv_path = \"D:\\\\111project\\\\gitHub\\\\041-111project\\\\data\\\\history_report_CalcOnly.csv\"\n",
    "data_csv_path = {\"ALL\":\"D:\\\\111project\\\\gitHub\\\\041-111project\\\\data\\\\Calc_ALL.csv\",\n",
    "                 \"CC\":\"D:\\\\111project\\\\gitHub\\\\041-111project\\\\data\\\\Calc_CC.csv\",\n",
    "                 \"MLO\":\"D:\\\\111project\\\\gitHub\\\\041-111project\\\\data\\\\Calc_MLO.csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ada7c2-e2f1-4c48-8c5d-a16b42aee608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1802/1802 [00:01<00:00, 1434.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#Prepare data for feeding into the model \n",
    "\n",
    "\n",
    "df = pd.read_csv(data_csv_path[DATA_TYPE]) #['Benign', 'CC', 'Calc', 'MLO', 'Mass', 'Melignant']\n",
    "# DATA_CLASS = list(df.columns)[2:]\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    img = image.load_img(join_path(IMG_DIR ,df['img_name'][i]),target_size=IMG_SIZE)\n",
    "    img = image.img_to_array(img)\n",
    "    # img = img/255. #imma use keras layers to preprocess imgs\n",
    "    X_dataset.append(img)\n",
    "    \n",
    "X = np.array(X_dataset)\n",
    "y = np.array(df.drop(['img_name','Calc/Mass','R/L', 'CC/MLO', 'Benign/Malignant'],axis=1))\n",
    "\n",
    "\n",
    "# split the data into 70% as training set and 30% as testing set \n",
    "X_train, X_test ,y_train , y_test = train_test_split(X,y,random_state=12,test_size=0.3,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd60197-7072-457f-a443-a2e0ea6d229a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test if data import correctly\n",
    "# if show_detail:\n",
    "#     imgs = X_train[0:9]\n",
    "#     labels = y_train[0:9]\n",
    "#     imgs = imgs/255.\n",
    "#     plot_imgs(imgs,labels)\n",
    "\n",
    "#     imgs_1 = X_test[0:9]\n",
    "#     labels_1 = y_test[0:9]\n",
    "#     imgs_1 = imgs_1/255.\n",
    "#     plot_imgs(imgs_1,labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "431f904e-fac8-42fc-ab45-613f43462e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet121 Model Created.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " Data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n",
      " al)                                                             \n",
      "                                                                 \n",
      " tf.math.truediv_4 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.nn.bias_add_2 (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " tf.math.truediv_5 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 50176)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                1605664   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,643,362\n",
      "Trainable params: 1,605,794\n",
      "Non-trainable params: 7,037,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Combined models into one cell and use model_name to choose\n",
    "\n",
    "if model_name == \"DenseNet\":\n",
    "    \n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    ],name=\"Data_augmentation\")\n",
    "    \n",
    "    base_model = tf.keras.applications.DenseNet121(input_shape=(IMG_SIZE[0],IMG_SIZE[1],3),include_top=False,weights=None)\n",
    "    base_model.load_weights(\"D:\\\\111project\\\\gitHub\\\\041-111project\\\\data\\\\models\\\\DenseNet-BC-121-32-no-top.h5\")\n",
    "    base_model.trainable = False\n",
    "\n",
    "    preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "    flatten_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "    prediction_layer = tf.keras.layers.Dense(len(DATA_CLASS),activation=\"softmax\")\n",
    "\n",
    "    inputs = tf.keras.Input(shape=IMG_SIZE)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x)\n",
    "    # Our FC layer\n",
    "    flat1 = Flatten()(x)\n",
    "    \n",
    "    dense1 = Dense(units=256, use_bias=True)(flat1)\n",
    "    batchnorm1 = BatchNormalization()(dense1)\n",
    "    act1 = Activation(activation='relu')(batchnorm1)\n",
    "    drop1 = Dropout(rate=0.5)(act1)\n",
    "\n",
    "    dense1 = Dense(units=32, use_bias=True)(flat1)\n",
    "    batchnorm1 = BatchNormalization()(dense1)\n",
    "    act1 = Activation(activation='relu')(batchnorm1)\n",
    "    drop1 = Dropout(rate=0.3)(act1)\n",
    "    # Output\n",
    "    out = Dense(units=2, activation='softmax')(drop1)\n",
    "\n",
    "    # Create Model\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "    if show_detail == True:\n",
    "        print(\"{}121 Model Created.\".format(model_name))\n",
    "        model.summary()\n",
    "    \n",
    "else:     \n",
    "    # Data Augmentation\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    ],name=\"Data_augmentation\")\n",
    "\n",
    "    #--- --- --- --- 分隔線 --- --- --- ---#        \n",
    "\n",
    "    if model_name == \"MobileNet\":\n",
    "\n",
    "        #Rescale Pixel Values\n",
    "        preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "        #MobileNet itself\n",
    "        base_model = tf.keras.applications.MobileNetV2(input_shape = IMG_SIZE,\n",
    "                                                        include_top=False,\n",
    "                                                          weights=\"imagenet\")\n",
    "        base_model.trainable = False\n",
    "\n",
    "    #--- --- --- --- 分隔線 --- --- --- ---#        \n",
    "\n",
    "    elif model_name == \"Inception\":\n",
    "\n",
    "        #Rescale Pixel Values\n",
    "        preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "        #MobileNet itself\n",
    "\n",
    "        base_model=tf.keras.applications.inception_v3.InceptionV3(\n",
    "                    include_top=False,\n",
    "                    weights='imagenet',\n",
    "                    input_tensor=None,\n",
    "                    input_shape=IMG_SIZE,\n",
    "                    pooling=None,\n",
    "                    classes=1000,\n",
    "                    classifier_activation='softmax'\n",
    "        )\n",
    "\n",
    "        base_model.trainable = False\n",
    "\n",
    "    #--- --- --- --- 分隔線 --- --- --- ---#        \n",
    "\n",
    "    elif model_name == \"VGG\":\n",
    "\n",
    "        #Rescale Pixel Values\n",
    "        preprocess_input = tf.keras.applications.vgg19.preprocess_input\n",
    "\n",
    "        #VGG19 itself\n",
    "        base_model = VGG19(weights='imagenet',include_top=False)\n",
    "        base_model.trainable = False   \n",
    "\n",
    "    #--- --- --- --- 分隔線 --- --- --- ---#        \n",
    "\n",
    "    # global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    flatten_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "    prediction_layer = tf.keras.layers.Dense(len(DATA_CLASS),activation=\"softmax\")\n",
    "\n",
    "\n",
    "    # # Assemble all together\n",
    "    inputs = tf.keras.Input(shape=IMG_SIZE)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x,training=False)\n",
    "    x = flatten_layer(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs,outputs)\n",
    "\n",
    "    if show_detail == True:\n",
    "        print(\"{} Model Created.\".format(model_name))\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47859cc9-eeec-4ac3-83ad-f7cf363752fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate),loss = tf.keras.losses.binary_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b24cf6cc-1bb1-486d-8010-e308d45a0713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 5s 64ms/step - loss: 0.7678 - accuracy: 0.4991\n",
      "initial loss: 0.77\n",
      "initial accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "loss0,accuracy0 = model.evaluate(x=X_test,y=y_test,batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197f547-af74-4c6a-972d-d512a5706fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40/40 [==============================] - 6s 88ms/step - loss: 0.8125 - accuracy: 0.4734 - val_loss: 0.7242 - val_accuracy: 0.5545\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.7482 - accuracy: 0.5575 - val_loss: 0.7431 - val_accuracy: 0.5434\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.7209 - accuracy: 0.5892 - val_loss: 0.7544 - val_accuracy: 0.5490\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6967 - accuracy: 0.6154 - val_loss: 0.7301 - val_accuracy: 0.5730\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.6802 - accuracy: 0.6368 - val_loss: 0.7149 - val_accuracy: 0.6044\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6724 - accuracy: 0.6400 - val_loss: 0.6950 - val_accuracy: 0.6100\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6554 - accuracy: 0.6431 - val_loss: 0.6918 - val_accuracy: 0.6174\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6537 - accuracy: 0.6598 - val_loss: 0.6820 - val_accuracy: 0.6303\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6448 - accuracy: 0.6534 - val_loss: 0.6773 - val_accuracy: 0.6359\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6287 - accuracy: 0.6772 - val_loss: 0.6625 - val_accuracy: 0.6377\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 0.6231 - accuracy: 0.6820 - val_loss: 0.6556 - val_accuracy: 0.6414\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6128 - accuracy: 0.6979 - val_loss: 0.6590 - val_accuracy: 0.6377\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6047 - accuracy: 0.6955 - val_loss: 0.6540 - val_accuracy: 0.6470\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6088 - accuracy: 0.6915 - val_loss: 0.6502 - val_accuracy: 0.6451\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.6076 - accuracy: 0.6875 - val_loss: 0.6504 - val_accuracy: 0.6654\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 3s 68ms/step - loss: 0.5841 - accuracy: 0.7185 - val_loss: 0.6513 - val_accuracy: 0.6617\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 3s 67ms/step - loss: 0.5855 - accuracy: 0.7105 - val_loss: 0.6440 - val_accuracy: 0.6617\n",
      "Epoch 18/30\n",
      " 8/40 [=====>........................] - ETA: 1s - loss: 0.5863 - accuracy: 0.7109"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=epochs, validation_data=(X_test,y_test), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d8acf-d62e-428d-a257-971dd8459f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0c482-bef9-4e76-aeac-fb81c6728277",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(predictions,axis=-1)\n",
    "y_true=np.argmax(y_test,axis=-1)\n",
    "cm = confusion_matrix(y_true=y_true,y_pred=y_pred)\n",
    "cm_container = convert_cm_to_container(cm)\n",
    "report = classification_report(y_true=y_true,y_pred=y_pred,target_names=DATA_CLASS)\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b3a56-64ca-4a49-8c7e-38157e1ea23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note=\"one extra layers for fully connected layer(Dense,BN,Dropout)\"\n",
    "note=\"With custom fully connected layer\"\n",
    "# note = \"None\"\n",
    "\n",
    "history_report = pd.read_csv(report_csv_path)\n",
    "history_report.loc[len(history_report)]=(time.ctime(time.time()),\n",
    "                                            model_name,\n",
    "                                            BATCH_SIZE,\n",
    "                                            epochs,\n",
    "                                            learning_rate,\n",
    "                                            report,\n",
    "                                            cm_container,\n",
    "                                            convert_list_to_str(acc),\n",
    "                                            convert_list_to_str(val_acc),\n",
    "                                            convert_list_to_str(loss),\n",
    "                                            convert_list_to_str(val_loss),\n",
    "                                            DATA_TYPE,\n",
    "                                            note)\n",
    "history_report.to_csv(report_csv_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee9054-c55f-4bbf-a969-2f3c4a23d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_report(-1,show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f600d-8315-4baf-aa47-2fabb5c963c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
